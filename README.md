# ğŸ§  Stroke Data Preprocessing Project

## ğŸ“Œ Introduction
This project focuses on **data cleaning and preprocessing** for a **stroke prediction dataset**.  
The goal is to handle missing values, encode categorical features, and normalize numerical attributes so the data can be used effectively in machine learning models for stroke prediction.

## ğŸ› ï¸ Workflow

1. **Data Loading**  
   - Source: `data_dotquy.csv`  
   - Loaded using `pandas`.

2. **Data Cleaning**
   - Remove duplicate records based on `id`.
   - Handle missing values:
     - Apply **KNN Imputer** to fill missing values in the `bmi` column.
   - Drop unnecessary columns (`id`).

3. **Categorical Encoding**
   - Gender (`gender`): Male â†’ 0, Female â†’ 1 (drop *Other*).
   - Marital status (`ever_married`): No â†’ 0, Yes â†’ 1.
   - Work type (`work_type`): Encoded using **LabelEncoder**.
   - Residence type (`Residence_type`): Rural â†’ 0, Urban â†’ 1.

4. **Numerical Normalization**
   - Age (`age`), average glucose level (`avg_glucose_level`), and BMI (`bmi`) normalized using **Min-Max Scaling**.
## ğŸ“š Technologies Used
- Python
- pandas, numpy
- scikit-learn (KNN Imputer, LabelEncoder, MinMaxScaler)
- matplotlib / seaborn (for data visualization)

## ğŸš€ Future Development
- Apply machine learning models (Logistic Regression, Random Forest) to predict stroke risk.
- Perform deeper data visualization (histograms, correlation heatmaps).
- Optimize preprocessing pipeline for scalability.

## ğŸ‘©â€ğŸ’» Contributors
- Hien
- Chau
- Chi
- Giang
- Hoang
